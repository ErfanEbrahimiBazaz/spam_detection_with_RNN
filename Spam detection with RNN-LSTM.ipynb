{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repo is a complementary to [my other git repo](https://github.com/ErfanEbrahimiBazaz/spam_detection_with_nltk) for spam detection.\n",
    "\n",
    "In [my previous repo](https://github.com/ErfanEbrahimiBazaz/spam_detection_with_nltk) we constructed a TF-IDF vector and trained a naive Baise network for spam detection. In this repository we use LSTM for spam detection. Both repositories work with the same data set.\n",
    "\n",
    "I make use of [this link](https://towardsdatascience.com/spam-detection-in-emails-de0398ea3b48) to implement the code. Some of the methods in the link are not implemented properly but altogether it shows the big picture and the logic behind text classification. Some minor changes were necessary to methods like remove_stop_words which I have corrected in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Embedding is the process of converting formatted text data into numerical values/vectors which a machine can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 32)            1600      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 53,345\n",
      "Trainable params: 53,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense,LSTM, Embedding, Dropout, Activation, Bidirectional\n",
    "\n",
    "\n",
    "# The length of all tokenized emails post-padding is set using ‘max_len’\n",
    "max_len = 50\n",
    "\n",
    "\n",
    "#size of the output vector from each layer\n",
    "embedding_vector_length = 32\n",
    "#Creating a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "#Creating an embedding layer to vectorize\n",
    "max_feature=50\n",
    "model.add(Embedding(max_feature, embedding_vector_length, input_length=max_len))\n",
    "#Addding Bi-directional LSTM\n",
    "model.add(Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "#Relu allows converging quickly and allows backpropagation\n",
    "model.add(Dense(16, activation='relu'))\n",
    "#Deep Learninng models can be overfit easily, to avoid this, we add randomization using drop out\n",
    "model.add(Dropout(0.1))\n",
    "#Adding sigmoid activation function to normalize the output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train_features, train_y, batch_size=512, epochs=20, validation_data=(x_test_features, test_y))\n",
    "y_predict = [1 if o>0.5 else 0 for o in model.predict(x_test_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "According to [this link](https://towardsdatascience.com/spam-detection-in-emails-de0398ea3b48):\n",
    "\n",
    "\"Precision and recall are the two most widely used performance metrics for a classification problem to get a better understanding of the problem. Precision is the fraction of the relevant instances from all the retrieved instances. Precision helps us to understand how useful the results are. The recall is the fraction of relevant instances from all the relevant instances. Recall helps us understand how complete the results are.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score\n",
    "\n",
    "\n",
    "cf_matrix =confusion_matrix(test_y,y_predict)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y,y_predict).ravel()\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(test_y, y_predict)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(test_y, y_predict)))\n",
    "print(\"F1 Score: {:.2f}%\".format(100 * f1_score(test_y,y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ax= plt.subplot()\n",
    "#annot=True to annotate cells\n",
    "sns.heatmap(cf_matrix, annot=True, ax = ax,cmap='Blues',fmt='');\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');\n",
    "ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data to train an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot, Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['Well done!',\n",
    "'Good work',\n",
    "'Great effort',\n",
    "'nice work',\n",
    "'Excellent!',\n",
    "'Weak',\n",
    "'Poor effort!',\n",
    "'not good',\n",
    "'poor work',\n",
    "'Could have done better.']\n",
    "labels = [1,1,1,1,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'sample', 'text', 'to', 'tokenize']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'a sample text to tokenize'\n",
    "tokens = text_to_word_sequence(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3, 3, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(text,5,lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 1.75, 5.25, 1.0, 3.25]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(text,5*1.25,lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: It is not indeed one hot encoding, but a vector of ints with 1s in different positions to map the input text to a number, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is WorkSpace\n",
      " Volume Serial Number is 6AD8-FF46\n",
      "\n",
      " Directory of E:\\Fad\\Advpy\\s13\\hw\n",
      "\n",
      "06/01/2021  12:39 PM    <DIR>          .\n",
      "06/01/2021  12:39 PM    <DIR>          ..\n",
      "06/01/2021  12:25 PM    <DIR>          .ipynb_checkpoints\n",
      "05/31/2021  09:28 PM            14,478 label.txt\n",
      "05/31/2021  09:26 PM            17,977 labels.txt\n",
      "06/01/2021  02:56 AM             6,216 predicted_lbl.csv\n",
      "06/01/2021  02:51 AM             6,216 predicted_lbl.txt\n",
      "05/30/2021  01:48 AM               556 README.md\n",
      "06/01/2021  12:39 PM            92,870 Spam detection with RNN-LSTM.ipynb\n",
      "06/01/2021  03:25 AM           115,507 Spam detection with RNN.ipynb\n",
      "05/31/2021  09:10 PM           916,713 spam detection.ipynb\n",
      "06/01/2021  02:28 AM           170,099 test.txt\n",
      "05/30/2021  01:57 AM            69,549 Text_Mining_Session02.ipynb\n",
      "05/31/2021  09:28 PM           292,475 train.txt\n",
      "01/01/2021  09:03 PM            18,837 word_embedding_with_keras .ipynb\n",
      "              12 File(s)      1,721,493 bytes\n",
      "               3 Dir(s)  45,656,301,568 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_concat_datasets(train_dataset='train.txt', labels='label.txt', delimiter = \"\\n\"):\n",
    "    df = pd.read_csv(train_dataset, delimiter = delimiter, header=None, quotechar=\"'\" )\n",
    "    df.columns = ['message']\n",
    "    \n",
    "    df_label = pd.read_csv(labels, delimiter=delimiter, header = None, quotechar=\"'\")\n",
    "    df_label.columns = ['message_type']\n",
    "    \n",
    "    df_final = pd.concat([df, df_label], axis=1)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The error \"ParserError: Error tokenizing data. C error: Expected 1 fields in line 8, saw 2\" is because of having comma in a field where using pd.read_csv().\n",
    "\n",
    "To resolve the error refer to [this link](https://stackoverflow.com/questions/32743479/pandas-read-csv-with-extra-commas-in-column). To resolve the issue, use  quotechar=\"'\" in pd.read_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The basket's gettin full so I might be by tonight</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can i get your opinion on something first?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company is very good.environment is terrific a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Its a valentine game. . . Send dis msg to all ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.i'm watching it in live..</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Don know:)this week i'm going to tirunelvai da.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7 lor... Change 2 suntec... Wat time u coming?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Garbage bags, eggs, jam, bread, hannaford whe...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You see the requirements please</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Are you being good, baby? :)\"</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message message_type\n",
       "0  The basket's gettin full so I might be by tonight          ham\n",
       "1         Can i get your opinion on something first?          ham\n",
       "2  Company is very good.environment is terrific a...          ham\n",
       "3  Its a valentine game. . . Send dis msg to all ...          ham\n",
       "4                        S.i'm watching it in live..          ham\n",
       "5    Don know:)this week i'm going to tirunelvai da.          ham\n",
       "6     7 lor... Change 2 suntec... Wat time u coming?          ham\n",
       "7  \"Garbage bags, eggs, jam, bread, hannaford whe...          ham\n",
       "8                    You see the requirements please          ham\n",
       "9                     \"Are you being good, baby? :)\"          ham"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_and_concat_datasets().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>Ok lor. I'm in town now lei.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>\"Aight I've been set free, think you could tex...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>No no:)this is kallis home ground.amla home to...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>excellent. I spent  &amp;lt;#&amp;gt;  years in the Ai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>Watching tv lor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message message_type\n",
       "3497                       Ok lor. I'm in town now lei.          ham\n",
       "3498  \"Aight I've been set free, think you could tex...          ham\n",
       "3499  No no:)this is kallis home ground.amla home to...          ham\n",
       "3500  excellent. I spent  &lt;#&gt;  years in the Ai...          NaN\n",
       "3501                                 Watching tv lor...          NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_and_concat_datasets()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is length mismatch. Downloading data sets again to start the work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining length of one-hot encoder to avoid collision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.txt', delimiter = \"\\n\", header=None )\n",
    "df.columns = ['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The basket's gettin full so I might be by tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can i get your opinion on something first?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company is very good.environment is terrific a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Its a valentine game. . . Send dis msg to all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.i'm watching it in live..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Don know:)this week i'm going to tirunelvai da.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7 lor... Change 2 suntec... Wat time u coming?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Garbage bags, eggs, jam, bread, hannaford whea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You see the requirements please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Are you being good, baby? :)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  The basket's gettin full so I might be by tonight\n",
       "1         Can i get your opinion on something first?\n",
       "2  Company is very good.environment is terrific a...\n",
       "3  Its a valentine game. . . Send dis msg to all ...\n",
       "4                        S.i'm watching it in live..\n",
       "5    Don know:)this week i'm going to tirunelvai da.\n",
       "6     7 lor... Change 2 suntec... Wat time u coming?\n",
       "7  Garbage bags, eggs, jam, bread, hannaford whea...\n",
       "8                    You see the requirements please\n",
       "9                       Are you being good, baby? :)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('label.txt', delimiter='\\n', header = None)\n",
    "df_label.columns = ['message_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message_type\n",
       "0          ham\n",
       "1          ham\n",
       "2          ham\n",
       "3          ham\n",
       "4          ham"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>Ok lor. I'm in town now lei.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>Aight I've been set free, think you could text...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>No no:)this is kallis home ground.amla home to...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>excellent. I spent  &amp;lt;#&amp;gt;  years in the Ai...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>Watching tv lor...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message message_type\n",
       "3495                       Ok lor. I'm in town now lei.          ham\n",
       "3496  Aight I've been set free, think you could text...          ham\n",
       "3497  No no:)this is kallis home ground.amla home to...          ham\n",
       "3498  excellent. I spent  &lt;#&gt;  years in the Ai...          ham\n",
       "3499                                 Watching tv lor...          ham"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, df_label],axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(message) for message in df[\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec_len = math.ceil(max([len(message) for message in df[\"message\"]]) * 1.25)\n",
    "one_hot_vec_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = [one_hot(message, one_hot_vec_len) for message in df[\"message\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[761, 1091, 15]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs[3499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(enc_doc) for enc_doc in encoded_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3078 [37, 960, 546, 942, 762, 347, 864, 399, 947, 762, 386, 1099, 947, 253, 655, 108, 1056, 3, 960, 952, 762, 902, 546, 559, 687, 110, 918, 183, 445, 511, 947, 209, 347, 546, 617, 873, 377, 20, 864, 655, 952, 762, 902, 345, 108, 1056, 947, 651, 942, 195, 902, 857, 1036, 445, 108, 1003, 257, 655, 409, 445, 102, 762, 182, 3, 655, 445, 102, 195, 902, 933, 80, 655, 947, 209, 707, 37, 655, 195, 989, 18, 445, 664, 873, 662, 18, 655, 391, 947, 195, 902, 362, 80, 12, 864, 30, 37, 655, 947, 195, 902, 183, 942, 1036, 947, 195, 902, 871, 546, 428, 724, 37, 655, 942, 195, 902, 1036, 947, 307, 887, 80, 358, 30, 1099, 445, 651, 977, 546, 1043, 1055, 769, 1101, 546, 1127, 775, 947, 195, 940, 902, 795, 552, 37, 655, 942, 195, 902, 1036, 947, 347, 914, 1101, 384, 746, 873, 377, 914, 784, 530, 102, 195, 902, 546, 1043, 1055, 857, 195, 1086, 108, 964, 873, 576, 1085, 37, 546, 617, 558, 952, 977, 864, 960, 947, 209, 793, 80, 131, 964, 1040, 195, 493, 132]\n"
     ]
    }
   ],
   "source": [
    "# bad way\n",
    "i = 0\n",
    "for enc_doc in encoded_docs:\n",
    "    i += 1\n",
    "    if len(enc_doc) == max([len(enc_doc) for enc_doc in encoded_docs]):\n",
    "        print(i,  enc_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You do got a shitload of diamonds though'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"message\"].iloc[3078 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>hi baby im cruisin with my girl friend what r ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message\n",
       "771  hi baby im cruisin with my girl friend what r ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"message\"]==\"hi baby im cruisin with my girl friend what r u up 2? give me a call in and hour at home if thats alright or fone me on this fone now love jenny xxx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[546 450 974 195 445 947  84 902 531  58   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(enc_doc) for enc_doc in encoded_docs])\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message    The basket's gettin full so I might be by tonight\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 189, 32)           36416     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 88,161\n",
      "Trainable params: 88,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,LSTM, Embedding, Dropout, Activation, Bidirectional\n",
    "from keras import Sequential\n",
    "\n",
    "\n",
    "#size of the output vector from each layer\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "#Creating an embedding layer to vectorize\n",
    "#max_feature is 1.25 * length of the mapping space.\n",
    "model.add(Embedding(one_hot_vec_len, embedding_vector_length, input_length=max_length))\n",
    "#Addding Bi-directional LSTM\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "#Relu allows converging quickly and allows backpropagation\n",
    "model.add(Dense(16, activation='relu'))\n",
    "#Deep Learninng models can be overfit easily, to avoid this, we add randomization using drop out\n",
    "model.add(Dropout(0.1))\n",
    "#Adding sigmoid activation function to normalize the output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ham\n",
       "1       ham\n",
       "2       ham\n",
       "3       ham\n",
       "4       ham\n",
       "       ... \n",
       "3495    ham\n",
       "3496    ham\n",
       "3497    ham\n",
       "3498    ham\n",
       "3499    ham\n",
       "Name: message_type, Length: 3500, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"message_type\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lables must be encoded to numerical value, otherwise, there will be the following error:\n",
    "\n",
    "UnimplementedError:  Cast string to float is not supported\n",
    "\t [[node binary_crossentropy/Cast (defined at <ipython-input-39-c86fac56b2a7>:1) ]] [Op:__inference_train_function_5826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels_enc = le.fit_transform(labels)\n",
    "\n",
    "labels_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_sr = pd.Series(labels_enc)[:15]\n",
    "label_sr.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ham\n",
       "1      ham\n",
       "2      ham\n",
       "3      ham\n",
       "4      ham\n",
       "5      ham\n",
       "6      ham\n",
       "7      ham\n",
       "8      ham\n",
       "9      ham\n",
       "10     ham\n",
       "11     ham\n",
       "12     ham\n",
       "13    spam\n",
       "14    spam\n",
       "Name: message_type, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"message_type\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df.assign(e = pd.Series(labels_enc).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The basket's gettin full so I might be by tonight</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can i get your opinion on something first?</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company is very good.environment is terrific a...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Its a valentine game. . . Send dis msg to all ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.i'm watching it in live..</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message message_type  e\n",
       "0  The basket's gettin full so I might be by tonight          ham  0\n",
       "1         Can i get your opinion on something first?          ham  0\n",
       "2  Company is very good.environment is terrific a...          ham  0\n",
       "3  Its a valentine game. . . Send dis msg to all ...          ham  0\n",
       "4                        S.i'm watching it in live..          ham  0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.assign(labels = labels_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The basket's gettin full so I might be by tonight</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can i get your opinion on something first?</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company is very good.environment is terrific a...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Its a valentine game. . . Send dis msg to all ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.i'm watching it in live..</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Don know:)this week i'm going to tirunelvai da.</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7 lor... Change 2 suntec... Wat time u coming?</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Garbage bags, eggs, jam, bread, hannaford whea...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You see the requirements please</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Are you being good, baby? :)</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ok, be careful ! Don't text and drive !</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HI ITS JESS I DONT KNOW IF YOU ARE AT WORK BUT...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I cant pick the phone right now. Pls send a me...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ringtoneking 84484</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>No 1 POLYPHONIC tone 4 ur mob every week! Just...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message message_type  labels\n",
       "0   The basket's gettin full so I might be by tonight          ham       0\n",
       "1          Can i get your opinion on something first?          ham       0\n",
       "2   Company is very good.environment is terrific a...          ham       0\n",
       "3   Its a valentine game. . . Send dis msg to all ...          ham       0\n",
       "4                         S.i'm watching it in live..          ham       0\n",
       "5     Don know:)this week i'm going to tirunelvai da.          ham       0\n",
       "6      7 lor... Change 2 suntec... Wat time u coming?          ham       0\n",
       "7   Garbage bags, eggs, jam, bread, hannaford whea...          ham       0\n",
       "8                     You see the requirements please          ham       0\n",
       "9                        Are you being good, baby? :)          ham       0\n",
       "10            Ok, be careful ! Don't text and drive !          ham       0\n",
       "11  HI ITS JESS I DONT KNOW IF YOU ARE AT WORK BUT...          ham       0\n",
       "12  I cant pick the phone right now. Pls send a me...          ham       0\n",
       "13                                 ringtoneking 84484         spam       1\n",
       "14  No 1 POLYPHONIC tone 4 ur mob every week! Just...         spam       1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df1[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "Epoch 2/40\n",
      "Epoch 3/40\n",
      "Epoch 4/40\n",
      "Epoch 5/40\n",
      "Epoch 6/40\n",
      "Epoch 7/40\n",
      "Epoch 8/40\n",
      "Epoch 9/40\n",
      "Epoch 10/40\n",
      "Epoch 11/40\n",
      "Epoch 12/40\n",
      "Epoch 13/40\n",
      "Epoch 14/40\n",
      "Epoch 15/40\n",
      "Epoch 16/40\n",
      "Epoch 17/40\n",
      "Epoch 18/40\n",
      "Epoch 19/40\n",
      "Epoch 20/40\n",
      "Epoch 21/40\n",
      "Epoch 22/40\n",
      "Epoch 23/40\n",
      "Epoch 24/40\n",
      "Epoch 25/40\n",
      "Epoch 26/40\n",
      "Epoch 27/40\n",
      "Epoch 28/40\n",
      "Epoch 29/40\n",
      "Epoch 30/40\n",
      "Epoch 31/40\n",
      "Epoch 32/40\n",
      "Epoch 33/40\n",
      "Epoch 34/40\n",
      "Epoch 35/40\n",
      "Epoch 36/40\n",
      "Epoch 37/40\n",
      "Epoch 38/40\n",
      "Epoch 39/40\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e22fd4f730>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, labels, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 4s 32ms/step - loss: 2.6669e-05 - accuracy: 1.0000 0s - loss: 2.6672e-05 - accuracy: \n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.txt', delimiter='\\n', header=None, quotechar=\"'\")\n",
    "df_test.columns = [\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>Our Prashanthettan's mother passed away last n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>either way works for me. I am  &amp;lt;#&amp;gt;  year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>Not yet had..ya sapna aunty manege y'day hogid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>What happen dear. Why you silent. I am tensed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>Don't b floppy... b snappy &amp; happy! Only gay c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "2067  Our Prashanthettan's mother passed away last n...\n",
       "2068  either way works for me. I am  &lt;#&gt;  year...\n",
       "2069  Not yet had..ya sapna aunty manege y'day hogid...\n",
       "2070      What happen dear. Why you silent. I am tensed\n",
       "2071  Don't b floppy... b snappy & happy! Only gay c..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_msg_len= math.ceil(max([len(message) for message in df_test[\"message\"]]) * 1.25)\n",
    "one_hot_msg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = [one_hot(msg, one_hot_msg_len) for msg in df_test[\"message\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400,\n",
       " 432,\n",
       " 69,\n",
       " 61,\n",
       " 86,\n",
       " 424,\n",
       " 61,\n",
       " 330,\n",
       " 331,\n",
       " 33,\n",
       " 736,\n",
       " 267,\n",
       " 264,\n",
       " 286,\n",
       " 400,\n",
       " 432,\n",
       " 14,\n",
       " 94,\n",
       " 470,\n",
       " 652,\n",
       " 33,\n",
       " 50]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Beautiful tomorrow never comes.. When it comes, it's already TODAY.. In the hunt of beautiful tomorrow don't waste your wonderful TODAY.. GOODMORNING:)\"\n",
    "encoded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message    \"Beautiful tomorrow never comes.. When it come...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Beautiful tomorrow never comes.. When it comes, it's already TODAY.. In the hunt of beautiful tomorrow don't waste your wonderful TODAY.. GOODMORNING:)\"\n",
    "df_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(message) for message in df_test[\"message\"]])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded_msgs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([400, 432,  69,  61,  86, 424,  61, 330, 331,  33, 736, 267, 264,\n",
       "       286, 400, 432,  14,  94, 470, 652,  33,  50,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded_msgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 189) for input Tensor(\"embedding_input:0\", shape=(None, 189), dtype=float32), but it was called on an input with incompatible shape (None, 590).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.4121206e-08],\n",
       "       [9.9986744e-01],\n",
       "       [3.4668432e-07],\n",
       "       ...,\n",
       "       [7.4099103e-07],\n",
       "       [9.4126940e-01],\n",
       "       [3.3551952e-08]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_padded_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_pred = model.predict(test_padded_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4121206e-08],\n",
       "       [9.9986744e-01],\n",
       "       [3.4668432e-07],\n",
       "       ...,\n",
       "       [7.4099103e-07],\n",
       "       [9.4126940e-01],\n",
       "       [3.3551952e-08]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4121206e-08"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999549], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(spam_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4121206e-08,\n",
       " 0.99986744,\n",
       " 3.4668432e-07,\n",
       " 3.3845222e-09,\n",
       " 5.6716118e-08,\n",
       " 2.821918e-05,\n",
       " 2.4148803e-06,\n",
       " 0.00025257468,\n",
       " 0.006676048,\n",
       " 1.2434184e-05]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_pred_list = []\n",
    "for i in range(len(spam_pred)):\n",
    "    spam_pred_list.append(spam_pred[i][0])\n",
    "    \n",
    "spam_pred_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_lables = [0 if val<0.5 else 1 for val in spam_pred_list ]\n",
    "predicted_lables[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_label\n",
       "0                0\n",
       "1                1\n",
       "2                0\n",
       "3                0\n",
       "4                0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lbl = pd.DataFrame(predicted_lables, columns=None)\n",
    "df_lbl.columns = ['predicted_label']\n",
    "df_lbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lbl.to_csv('predicted_lbl.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_label\n",
       "0                   0\n",
       "1                   1\n",
       "2                   0\n",
       "3                   0\n",
       "4                   0\n",
       "...               ...\n",
       "2067                1\n",
       "2068                0\n",
       "2069                0\n",
       "2070                1\n",
       "2071                0\n",
       "\n",
       "[2072 rows x 1 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving the warning\n",
    "\n",
    "Increase pad sequence for training model to the longest message in test data set; this means increasing the pad sequence from 189 to 590."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The basket's gettin full so I might be by tonight</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can i get your opinion on something first?</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company is very good.environment is terrific a...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Its a valentine game. . . Send dis msg to all ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.i'm watching it in live..</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message message_type  labels\n",
       "0  The basket's gettin full so I might be by tonight          ham       0\n",
       "1         Can i get your opinion on something first?          ham       0\n",
       "2  Company is very good.environment is terrific a...          ham       0\n",
       "3  Its a valentine game. . . Send dis msg to all ...          ham       0\n",
       "4                        S.i'm watching it in live..          ham       0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_vec_len = math.ceil(max([len(message) for message in df[\"message\"]]) * 1.25)\n",
    "encoded_docs = [one_hot(message, one_hot_vec_len) for message in df[\"message\"]]\n",
    "\n",
    "# set padded values from df_test where longest message is 590. This will train the model on the same length as the test df\n",
    "# against which messages are being tested. \n",
    "max_length = max([len(message) for message in df_test[\"message\"]])\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 590, 32)           36416     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 88,161\n",
      "Trainable params: 88,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#size of the output vector from each layer\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "#Creating an embedding layer to vectorize\n",
    "#max_feature is 1.25 * length of the mapping space.\n",
    "model.add(Embedding(one_hot_vec_len, embedding_vector_length, input_length=max_length))\n",
    "#Addding Bi-directional LSTM\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "#Relu allows converging quickly and allows backpropagation\n",
    "model.add(Dense(16, activation='relu'))\n",
    "#Deep Learninng models can be overfit easily, to avoid this, we add randomization using drop out\n",
    "model.add(Dropout(0.1))\n",
    "#Adding sigmoid activation function to normalize the output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: labels, dtype: int32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "110/110 [==============================] - 47s 428ms/step - loss: 0.3111 - accuracy: 0.8943\n",
      "Epoch 2/15\n",
      "110/110 [==============================] - 49s 444ms/step - loss: 0.0709 - accuracy: 0.9803\n",
      "Epoch 3/15\n",
      "110/110 [==============================] - 47s 423ms/step - loss: 0.0437 - accuracy: 0.9880\n",
      "Epoch 4/15\n",
      "110/110 [==============================] - 46s 421ms/step - loss: 0.0358 - accuracy: 0.9917\n",
      "Epoch 5/15\n",
      "110/110 [==============================] - 45s 412ms/step - loss: 0.0206 - accuracy: 0.9946\n",
      "Epoch 6/15\n",
      "110/110 [==============================] - 44s 402ms/step - loss: 0.0134 - accuracy: 0.9966\n",
      "Epoch 7/15\n",
      "110/110 [==============================] - 48s 438ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 8/15\n",
      "110/110 [==============================] - 45s 413ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 9/15\n",
      "110/110 [==============================] - 46s 418ms/step - loss: 0.1037 - accuracy: 0.9820\n",
      "Epoch 10/15\n",
      "110/110 [==============================] - 47s 430ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 11/15\n",
      "110/110 [==============================] - 48s 438ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "Epoch 12/15\n",
      "110/110 [==============================] - 48s 432ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 13/15\n",
      "110/110 [==============================] - 46s 421ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "110/110 [==============================] - 56s 508ms/step - loss: 7.4093e-04 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "110/110 [==============================] - 59s 533ms/step - loss: 3.9838e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebb508a2e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, labels, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 12s 109ms/step - loss: 8.3551e-05 - accuracy: 1.0000\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model is obviously overtrained. Either use a validation set for early stopping or reduce the number of epocs to 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the newly trained model on test data and check the website scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6338426e-07],\n",
       "       [3.3659030e-06],\n",
       "       [9.8079777e-01],\n",
       "       ...,\n",
       "       [3.6426886e-07],\n",
       "       [2.9595521e-06],\n",
       "       [1.5506515e-05]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.txt', delimiter='\\n', header=None, quotechar=\"'\")\n",
    "df_test.columns = [\"message\"]\n",
    "one_hot_msg_len= math.ceil(max([len(message) for message in df_test[\"message\"]]) * 1.25)\n",
    "encoded_docs = [one_hot(msg, one_hot_msg_len) for msg in df_test[\"message\"]]\n",
    "max_length = max([len(message) for message in df_test[\"message\"]])\n",
    "test_padded_msgs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "model.predict(test_padded_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We resolved the warning for mis-matched length of tokenized messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing network architecture and checking the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 590, 64)           72832     \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 590, 128)          66048     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 590, 16)           2064      \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 128)               41472     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 184,497\n",
      "Trainable params: 184,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(one_hot_vec_len, embedding_vector_length, input_length=max_length))\n",
    "\n",
    "#return_sequences: Boolean. Whether to return the last output. in the outpu sequence, or the full sequence. \n",
    "#Default: `False`. Change it to True to be able to stack LSTM layers. Otherwise, will get this error:\n",
    "# ValueError: Input 0 of layer bidirectional_8 is incompatible with the layer: expected ndim=3, found ndim=2. \n",
    "#Full shape received: [None, 16]\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "110/110 [==============================] - 97s 882ms/step - loss: 0.2497 - accuracy: 0.9134\n",
      "Epoch 2/15\n",
      "110/110 [==============================] - 97s 878ms/step - loss: 0.0667 - accuracy: 0.9820\n",
      "Epoch 3/15\n",
      "110/110 [==============================] - 101s 918ms/step - loss: 0.0409 - accuracy: 0.9906\n",
      "Epoch 4/15\n",
      "110/110 [==============================] - 98s 889ms/step - loss: 0.0302 - accuracy: 0.9940\n",
      "Epoch 5/15\n",
      "110/110 [==============================] - 98s 889ms/step - loss: 0.0204 - accuracy: 0.9951\n",
      "Epoch 6/15\n",
      "110/110 [==============================] - 110s 1s/step - loss: 0.0132 - accuracy: 0.9971\n",
      "Epoch 7/15\n",
      "110/110 [==============================] - 100s 914ms/step - loss: 0.0114 - accuracy: 0.9969\n",
      "Epoch 8/15\n",
      "110/110 [==============================] - 104s 947ms/step - loss: 0.0120 - accuracy: 0.9966\n",
      "Epoch 9/15\n",
      "110/110 [==============================] - 99s 897ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 10/15\n",
      "110/110 [==============================] - 98s 892ms/step - loss: 5.6757e-04 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "110/110 [==============================] - 99s 902ms/step - loss: 2.2877e-04 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "110/110 [==============================] - 98s 892ms/step - loss: 1.6055e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "110/110 [==============================] - 131s 1s/step - loss: 1.4399e-04 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "110/110 [==============================] - 158s 1s/step - loss: 9.9106e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "110/110 [==============================] - 337s 3s/step - loss: 8.3937e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebc94e8b20>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec_len = math.ceil(max([len(message) for message in df[\"message\"]]) * 1.25)\n",
    "encoded_docs = [one_hot(message, one_hot_vec_len) for message in df[\"message\"]]\n",
    "\n",
    "# set padded values from df_test where longest message is 590. This will train the model on the same length as the test df\n",
    "# against which messages are being tested. \n",
    "max_length = max([len(message) for message in df_test[\"message\"]])\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "model.fit(padded_docs, labels, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up early stopping in Keras model\n",
    "\n",
    "#### The model is again overtrained. To stop this define an EarlyStopping callback function and pass it to model.fit() together with 10% validation set. For more refer to [this](https://keras.io/api/callbacks/early_stopping/) and [this link](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/#:~:text=the%20validation%20dataset.-,Early%20Stopping%20in%20Keras,configured%20when%20instantiated%20via%20arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 947,  887,  961,   83,  594, 1095,  916,  519,  982,  735,  331,\n",
       "        878, 1109,  914,  960,  376,  561,  962,  947,  887,  855,  964,\n",
       "       1031,  327,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 590, 64)           72832     \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 590, 128)          66048     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 590, 16)           2064      \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 128)               41472     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 184,497\n",
      "Trainable params: 184,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(one_hot_vec_len, embedding_vector_length, input_length=max_length))\n",
    "\n",
    "#return_sequences: Boolean. Whether to return the last output. in the outpu sequence, or the full sequence. \n",
    "#Default: `False`. Change it to True to be able to stack LSTM layers. Otherwise, will get this error:\n",
    "# ValueError: Input 0 of layer bidirectional_8 is incompatible with the layer: expected ndim=3, found ndim=2. \n",
    "#Full shape received: [None, 16]\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "99/99 [==============================] - 82s 828ms/step - loss: 0.2540 - accuracy: 0.9181 - val_loss: 0.0803 - val_accuracy: 0.9771\n",
      "Epoch 2/15\n",
      "99/99 [==============================] - 81s 819ms/step - loss: 0.0803 - accuracy: 0.9768 - val_loss: 0.0775 - val_accuracy: 0.9800\n",
      "Epoch 3/15\n",
      "99/99 [==============================] - 84s 850ms/step - loss: 0.0449 - accuracy: 0.9886 - val_loss: 0.0858 - val_accuracy: 0.9800\n",
      "Epoch 4/15\n",
      "99/99 [==============================] - 85s 854ms/step - loss: 0.0277 - accuracy: 0.9946 - val_loss: 0.0521 - val_accuracy: 0.9829\n",
      "Epoch 5/15\n",
      "99/99 [==============================] - 82s 832ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.0391 - val_accuracy: 0.9914\n",
      "Epoch 6/15\n",
      "99/99 [==============================] - 83s 843ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.0713 - val_accuracy: 0.9886\n",
      "Epoch 7/15\n",
      "99/99 [==============================] - 89s 900ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.0600 - val_accuracy: 0.9857\n",
      "Epoch 8/15\n",
      "99/99 [==============================] - 94s 949ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.1026 - val_accuracy: 0.9857\n",
      "Epoch 9/15\n",
      "99/99 [==============================] - 88s 886ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0801 - val_accuracy: 0.9886\n",
      "Epoch 10/15\n",
      "99/99 [==============================] - 92s 931ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0931 - val_accuracy: 0.9886\n",
      "Epoch 11/15\n",
      "99/99 [==============================] - 84s 845ms/step - loss: 7.4900e-04 - accuracy: 0.9997 - val_loss: 0.1448 - val_accuracy: 0.9829\n",
      "Epoch 12/15\n",
      "99/99 [==============================] - 83s 837ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.1301 - val_accuracy: 0.9829\n",
      "Epoch 13/15\n",
      "99/99 [==============================] - 87s 877ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.1199 - val_accuracy: 0.9829\n",
      "Epoch 14/15\n",
      "99/99 [==============================] - 88s 889ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.1232 - val_accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebd8d19100>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, callbacks=[callback] ,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 30s 275ms/step - loss: 0.0144 - accuracy: 0.9980\n",
      "Train Accuracy: {99.80000257492065} --- Train Loss\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Train Accuracy: {} --- Train Loss'.format({accuracy*100}, {loss}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 25s 254ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "Train Accuracy: {99.96825456619263} --- Train Loss\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train Accuracy: {} --- Train Loss'.format({accuracy*100}, {loss}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 246ms/step - loss: 0.1232 - accuracy: 0.9829\n",
      "Train Accuracy: {98.28571677207947} --- Train Loss\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Train Accuracy: {} --- Train Loss'.format({accuracy*100}, {loss}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: Defning restore best weights in EarlyStopping callback\n",
    "\n",
    "```(python)\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "```\n",
    "Arguments\n",
    "\n",
    "+ monitor: Quantity to be monitored.\n",
    "+ min_delta: Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\n",
    "+ patience: Number of epochs with no improvement after which training will be stopped.\n",
    "+ verbose: verbosity mode.\n",
    "+ mode: One of {\"auto\", \"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing; in \"max\" mode it will stop when the quantity monitored has stopped increasing; in \"auto\" mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "+ baseline: Baseline value for the monitored quantity. Training will stop if the model doesn't show improvement over the baseline.\n",
    "+ restore_best_weights: Whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used. An epoch will be restored regardless of the performance relative to the baseline. If no epoch improves on baseline, training will run for patience epochs and restore weights from the best epoch in that set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 590, 64)           72832     \n",
      "_________________________________________________________________\n",
      "bidirectional_21 (Bidirectio (None, 590, 128)          66048     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 590, 16)           2064      \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 128)               41472     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 184,497\n",
      "Trainable params: 184,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 161s 3s/step - loss: 0.3820 - accuracy: 0.8673 - val_loss: 0.1550 - val_accuracy: 0.9514\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 158s 3s/step - loss: 0.0813 - accuracy: 0.9787 - val_loss: 0.0857 - val_accuracy: 0.9800\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 157s 2s/step - loss: 0.0416 - accuracy: 0.9895 - val_loss: 0.0892 - val_accuracy: 0.9771\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 166s 3s/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.1018 - val_accuracy: 0.9800\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 176s 3s/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.1190 - val_accuracy: 0.9771\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 174s 3s/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.1207 - val_accuracy: 0.9800\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 175s 3s/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.1669 - val_accuracy: 0.9714\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 158s 3s/step - loss: 0.0177 - accuracy: 0.9968 - val_loss: 0.1118 - val_accuracy: 0.9829\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 165s 3s/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1842 - val_accuracy: 0.9743\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 170s 3s/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1345 - val_accuracy: 0.9800\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 167s 3s/step - loss: 3.6306e-04 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9829\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 190s 3s/step - loss: 1.7948e-04 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9800\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 194s 3s/step - loss: 1.5788e-04 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9800\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 196s 3s/step - loss: 9.8899e-05 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9800\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 250s 4s/step - loss: 9.7685e-05 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebf8766d60>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector_length = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(one_hot_vec_len, embedding_vector_length, input_length=max_length))\n",
    "\n",
    "#return_sequences: Boolean. Whether to return the last output. in the outpu sequence, or the full sequence. \n",
    "#Default: `False`. Change it to True to be able to stack LSTM layers. Otherwise, will get this error:\n",
    "# ValueError: Input 0 of layer bidirectional_8 is incompatible with the layer: expected ndim=3, found ndim=2. \n",
    "#Full shape received: [None, 16]\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size = 0.1)\n",
    "\n",
    "# callback = EarlyStopping(monitor='loss', patience=3, baseline=0.001 , restore_best_weights=True)\n",
    "callback = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15,  batch_size=50, callbacks=[callback] ,verbose=1)\n",
    "\n",
    "# In epoc 3 it is failing due to this error:\n",
    "# TypeError: object of type 'NoneType' has no len(). \n",
    "# tensorboard               2.4.1                    pypi_0    pypi\n",
    "# tensorboard-plugin-wit    1.8.0                    pypi_0    pypi\n",
    "# tensorflow                2.4.1                    pypi_0    pypi\n",
    "# tensorflow-estimator      2.4.0                    pypi_0    pypi\n",
    "# termcolor                 1.1.0                    pypi_0    pypi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Is it a must that data set length be dividable by thenumber of batch size? If data set cannot be splitted into that chunk size, how will it behave? Can it cause failure in training or validating process? For example if training data has the length of 100, and the batch size is 60 (just example numbers), will it cause failure?\n",
    "\n",
    "### Q3: Epoch vs batch size\n",
    "\n",
    "In each epoc whole data is being fed into the network. At the end of each epoch there is a backpropagation. Batch size determines the size of each batch to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have made two changes to check the accuracy and loss of the new trained model:\n",
    "\n",
    "1. Stacking two LSTM layers.\n",
    "2. Adding a callback function for early stopping.\n",
    "3. Saving best weights of the trained model.\n",
    "4. changing batch size from 1 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 131s 1s/step - loss: 0.0177 - accuracy: 0.9980\n",
      "Train Accuracy: {99.80000257492065} --- Train Loss\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Train Accuracy: {} --- Train Loss'.format({accuracy*100}, {loss}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 117s 1s/step - loss: 2.1352e-05 - accuracy: 1.0000\n",
      "Train Accuracy: {100.0} --- Train Loss\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train Accuracy: {} --- Train Loss'.format({accuracy*100}, {loss}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 13s 1s/step - loss: 0.1771 - accuracy: 0.9800\n",
      "Train Accuracy: {98.00000190734863} --- Train Loss\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Train Accuracy: {} --- Train Loss'.format({accuracy*100}, {loss}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.txt', delimiter='\\n', header=None, quotechar=\"'\")\n",
    "df_test.columns = [\"message\"]\n",
    "one_hot_msg_len= math.ceil(max([len(message) for message in df_test[\"message\"]]) * 1.25)\n",
    "encoded_docs = [one_hot(msg, one_hot_msg_len) for msg in df_test[\"message\"]]\n",
    "\n",
    "max_length = max([len(message) for message in df_test[\"message\"]])\n",
    "test_padded_msgs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([313, 695, 473, 457, 538, 708, 457, 164, 687, 154, 721, 300,  81,\n",
       "       572, 313, 695,  40, 681, 631, 501, 154, 224,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded_msgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_pred = model.predict(test_padded_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8601212e-06"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8601212e-06,\n",
       " 1.169266e-05,\n",
       " 0.9961685,\n",
       " 1.0340724e-05,\n",
       " 3.7576624e-06,\n",
       " 1.04528435e-05,\n",
       " 1.2438679e-05,\n",
       " 5.3217914e-06,\n",
       " 1.800399e-05,\n",
       " 6.506518e-06]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_pred_list = []\n",
    "for i in range(len(spam_pred)):\n",
    "    spam_pred_list.append(spam_pred[i][0])\n",
    "    \n",
    "spam_pred_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_label\n",
       "0                0\n",
       "1                0\n",
       "2                1\n",
       "3                0\n",
       "4                0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_lables = [0 if val<0.5 else 1 for val in spam_pred_list ]\n",
    "df_lbl = pd.DataFrame(predicted_lables, columns=None)\n",
    "df_lbl.columns = ['predicted_label']\n",
    "df_lbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lbl.to_csv('predicted_lbl_2lstm_lyrs.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: What is the cause of \"TypeError: object of type 'NoneType' has no len() error\"? Why it was raised at the end of epoch 3? Why dropping \"baseline=0.001\" in callback function resolved the error? Check the cell below to see the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 590, 64)           72832     \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 590, 128)          66048     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 590, 16)           2064      \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 128)               41472     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 184,497\n",
      "Trainable params: 184,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "99/99 [==============================] - 104s 1s/step - loss: 0.4447 - accuracy: 0.8537 - val_loss: 0.3250 - val_accuracy: 0.8800\n",
      "Epoch 2/15\n",
      "99/99 [==============================] - 122s 1s/step - loss: 0.2075 - accuracy: 0.9337 - val_loss: 0.1395 - val_accuracy: 0.9543\n",
      "Epoch 3/15\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9667"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-63bfbbceb044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1675\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Restoring model weights from the end of the best epoch.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1677\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1803\u001b[0m         \u001b[0mexpected_num_weights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1805\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mexpected_num_weights\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1806\u001b[0m       raise ValueError(\n\u001b[0;32m   1807\u001b[0m           \u001b[1;34m'You called `set_weights(weights)` on layer \"%s\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(one_hot_vec_len, embedding_vector_length, input_length=max_length))\n",
    "\n",
    "#return_sequences: Boolean. Whether to return the last output. in the outpu sequence, or the full sequence. \n",
    "#Default: `False`. Change it to True to be able to stack LSTM layers. Otherwise, will get this error:\n",
    "# ValueError: Input 0 of layer bidirectional_8 is incompatible with the layer: expected ndim=3, found ndim=2. \n",
    "#Full shape received: [None, 16]\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size = 0.1)\n",
    "\n",
    "callback = EarlyStopping(monitor='loss', patience=3, baseline=0.001 , restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, callbacks=[callback] ,verbose=1)\n",
    "\n",
    "TypeError: object of type 'NoneType' has no len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_tf",
   "language": "python",
   "name": "python_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
